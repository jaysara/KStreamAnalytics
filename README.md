# KStreamAnalytics

Assuming you have Kafka broker and Zookeeper running locally in your environment with default settings. Following topics need to be created to run this program.
## Topics needed to run the program
### Policy Paid Topic
This topic has sample events generated by ```PolicyEventGenerator``` class. 

```script
./bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic policyPaid
```

### Policy Analytic Topic
This topic will have a generated stream created by ```PolicyEventProcessor``` class.
```script
./bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic policyAnalytic
```

When I run the prgram, I get following exception,

```stacktrace
org.apache.kafka.common.errors.SerializationException: Size of data received by LongDeserializer is not 8

2018-05-02 13:25:45.755  INFO 81062 --- [-StreamThread-2] o.a.k.s.p.internals.StreamThread         : stream-thread [panalytics-8d42c72e-9849-4cc3-80f7-dc5d6891d655-StreamThread-2] State transition from RUNNING to PENDING_SHUTDOWN
2018-05-02 13:25:45.758  INFO 81062 --- [-StreamThread-2] o.a.k.s.p.internals.StreamThread         : stream-thread [panalytics-8d42c72e-9849-4cc3-80f7-dc5d6891d655-StreamThread-2] Shutting down
2018-05-02 13:25:45.789  INFO 81062 --- [-StreamThread-2] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=panalytics-8d42c72e-9849-4cc3-80f7-dc5d6891d655-StreamThread-2-producer] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-05-02 13:25:45.793Exception in thread "panalytics-8d42c72e-9849-4cc3-80f7-dc5d6891d655-StreamThread-2" org.apache.kafka.streams.errors.StreamsException: Deserialization exception handler is set to fail upon a deserialization error. If you would rather have the streaming pipeline continue after a deserialization error, please set the default.deserialization.exception.handler appropriately.
  INFO	at org.apache.kafka.streams.processor.internals.RecordDeserializer.deserialize(RecordDeserializer.java:74)
 	at org.apache.kafka.streams.processor.internals.RecordQueue.addRawRecords(RecordQueue.java:91)
81062 	at org.apache.kafka.streams.processor.internals.PartitionGroup.addRawRecords(PartitionGroup.java:117)
--- 	at org.apache.kafka.streams.processor.internals.StreamTask.addRecords(StreamTask.java:549)
[-StreamThread-2] 	at org.apache.kafka.streams.processor.internals.StreamThread.addRecordsToTasks(StreamThread.java:920)
o.a.k.s.p.internals.StreamThread         	at org.apache.kafka.streams.processor.internals.StreamThread.runOnce(StreamThread.java:821)
:	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:774)
 stream-thread [panalytics-8d42c72e-9849-4cc3-80f7-dc5d6891d655-StreamThread-2] State transition from PENDING_SHUTDOWN to DEAD
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:744)

```
